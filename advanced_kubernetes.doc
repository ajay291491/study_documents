#-------------------------------------------------------------------------------------------------------------------------
# Chapter O1 - Kubernetes Core Concepts 
#-------------------------------------------------------------------------------------------------------------------------
#
# * Kubernetes at higher level
# Kubernetes is used to deploy and maintain the containers in a very effective and effecient manner, It has mainly few components such as master or contolr pland and worker node. 
# Master and worker has again few components so that it can work.
# 
# * Master Node or Control Plane 
# This is the place where all the control related activities on the cluster takes place, Master node take care of planning and deploying containers 
# There are mainly few components in master node which helps to achieve the same 
#
# . ETCD
# . Kube API Server
# . Kube Scheduler
# . Control manager 
#
# * Worker Node 
# This is where all pods gets deployed and containarized application running on top of them.
#
# Kubelet : Engine runs from each worker node which takes the instructions from the Master node and take actions on worker node to deploy or change containers 
# 	  : This also monitors the status of the containers in each node
#
# Kube Proxy : Communication between the Worker nodes are managed by the Kube Proxy service which makes sure the communication are establisehed for right level of policies 
#
# You can see all control components of the Kubernetes cluster are running in the "kube-system" name space and details can be found as below.
#
# | sathsang@sathsang-Predator-G3620:~$ kubectl get pods -n kube-system
# | NAME                                        READY   STATUS      RESTARTS   AGE
# | coredns-66bff467f8-rh7s8                    1/1     Running     2          6d17h
# | coredns-66bff467f8-zmgbp                    1/1     Running     2          6d17h
# | etcd-minikube                               1/1     Running     2          6d17h
# | ingress-nginx-admission-create-jbq4p        0/1     Completed   0          2d16h
# | ingress-nginx-admission-patch-j7nj7         0/1     Completed   2          2d16h
# | ingress-nginx-controller-7bb4c67d67-qjlb4   1/1     Running     2          2d16h
# | kube-apiserver-minikube                     1/1     Running     2          6d17h
# | kube-controller-manager-minikube            1/1     Running     2          6d17h
# | kube-proxy-l7g57                            1/1     Running     2          6d17h
# | kube-scheduler-minikube                     1/1     Running     2          6d17h
# | storage-provisioner                         1/1     Running     3          6d17h
# | sathsang@sathsang-Predator-G3620:~$
#
# * ETCD
# This is a key value pair (NOSQL) database which helps to maintain the state and information about the cluster
# Whenver there is an action or change happen in the cluster as part of the process all info will get updated in the ETC cluster
# When you run the kubectl GET commands all information are retrieved from the ETCD database
#
#
# * Role of Kube API Server 
# When you request a POD to get created then and send a instruction to Kubernetes cluster, below are the tasks which happens
# . Kube API server authenticate the user and make sure the request is authorized 
# . Then it validates the request
# . Then its retrieve the data from ETCD database and see if this is an existing POD or component information is requested for
# . If this is a GET request operations ends here and its a deployment request proceed further
# . Then the Kube API server contacts the Kubelet in the worker node and instructs to deploy the pods 
# . Once Kubelet updates the infromation about the actions are performed then it contacts ETCD databse to update the latest status of the pods 
#
# * Kube Scheduler 
# Scheuler is responsible for placing the right controller on a node based on the resource requirements 
# This also monitors for the node status taints are roles on them before placing a container on them
# Scheduler always look for the resources such CPU and memory in each node and based on the resource availibity its ranks them
# So when next time there is a requirement deploy a pod, then it finds the right node and pass the information to KUbe API server 
# Need to be careful and aware that Kube Scheduler won't deploy the Pod and that is the job of Kublet running on the worker node, but scheduler send the info that where it need to get deployed
#
# * Control manager 
# Control Manager will take care of the overall avalbilty and replication of the nodes, It has mainly two sub components 
# Control manager polls the nodes every 5 seconds for a node status if there no heartbeat recieved from the node for 40 seconds then it disable the node and move pods to other worker nodes
#  - Node Controller : Node controllers will make sure the status of the nodes 
#  - Replication Controller : Make sure desired number of containers and pods are running across the worker nodes in a replication mode
#
# * Kubelet
# Kubelet is responsible for registering the node in the Master and then also make sure to deploy the pods and containers
# When Kubelet receive a request from Kube API Server, it pass the message to the underlying Container runtime such as docket or Rocket 
# Then the underlying container runtime pull the image and runs the pods, then kubelet pass that info back to Kubeapi serever which gets registered in ETCD
#
# * Kube Proxy
# Kube proxy runs on every node in the kubernetes cluster to satisfy the networking needs by the pods 
# This helps inter pods communication by enabling the virtual networking services and these services stay in the memory.
# Kube Proxy achieve this by using the IP tables rules 
# 
# * Pod 
# Pod is smallest unit to run a container in kubernetes cluster, whenever we deploy a container it runs on a pod within worker node.
# In most of the scenarios a pod to container will be a one to one relationship and when we scale up or down a new container gets created or destroyed. 
# However if there helper containers or sidecars that can run along with the main container in the same pod, but this will be a very rare scenario.
#
# * Pod Definition YAML File 
# A Pod definition has maoinly 4 objects and details given below. 
#
# ---
# apiVersion: {v1 | appsV1}
# kind : 
# metadata:
#   name: {pod_name}
#   labels: 
#     {key} : {value}
# spec:
#   conatiners:
#     - name: {name of the container}
#       image: {location of the container image}
# ---
#
# * Replication Controller 
# Controllers are the brain behind kubernetes. Replication controller helps you to maintain replication of your pod across multiple nodes
# This also helps you for scaling and load balancing of your pods across multiple worker nodes in the cluster. 
# Even if you deploy a single pod object replication controller will help you to maintain the state of the pod if gets terminated.
# To define a replication controller object and to deploy a pod using replication controller you need to follow below synatx 
# 
# ---
# apiVersion: V1
# kind: ReplicationController 
# metadata:
#   name:  {name of the replication controller}
#   labels:
#     key_1: value_1
#     key_2: value_2
# spec:
#   template:
#     metadata:
#       name: {name of the pod}
#       labels:
#         key_1: value_1
#         key_2: value_2
#     spec:
#       containers:
#         - name: {name of the container}
#           image: {location of the image}
#
# replicas: {number of replicas}
# ---
#
# To apply and see the contents of the Replication Controller follow below commands 
#
# | $ kubectl create -f {replicatio_controller_config}.yml
# | $ kubectl get replicationcontroller
# | $ kubectl get pods
#
# * RepliaSet
# ReplicationSet is also similar to repliaction controller where ReplicationSet is the latest technology and ReplicaController is older
# This also supports scaling, resillency, loadbalancing etc similar to replication controller 
# This will also help you to maintain the state of the pod even if you are deploying only single pod in the cluster 
# Below is the sample for deploying a ReplicaSet
#
# ---
# apiVersion: apps/v1
# kind: ReplicaSet
# metadata:
#   name: {name of the replication set}
#   labels:
#     key_1: label_1
#     key_2: label_2
# spec:
#   template:
#     metadata:
#       name: {name of the pod}
#       labels:
#         key_1: value_1
#         key_2: value_2
#     spec:
#       containers:
#         - name : {name of the container}
#           image: {name of the image}
# replicas: {number of replicas }
# selector:
#   matchLabels:
#     key_1 : value_1   => This can be any key value pair mentioned in the labels section of the pod
# ---
#
# To apply and see the contents of the Replication Controller follow below commands 
#
# | $ kubectl create -f {replica_Set_config}.yml
# | $ kubectl get replicaset
# | $ kubectl get pods
#
# NOTE : Key difference between ReplicationController and ReplicaSet is the selector and the apiVersion. 
#        ReplicaSet can also manage pods which is not part of the replicaset definition, that is why we need to use selector there 
#
# * Difference between ReplicationController and ReplicationSet
#
